# v3.5.5 Release Notes: Report Review & Pipeline Suggestions

**Released:** 2026-01-19

## Overview

v3.5.5 adds an automated editorial review pass to the analytics pipeline. After the report is rendered, Gemini 3 Pro reviews the content for quality issues and suggests pipeline improvements for future runs.

## What Changed

### New Tool: `review_report.py`

A dedicated LLM-powered editorial review step that:

1. **Reviews for quality issues**
   - Factual inconsistencies (conflicting statements, numbers don't match)
   - Logical gaps (conclusions not supported by evidence)
   - Missing connections between related insights
   - Unclear language or jargon

2. **Tightens the prose**
   - Removes redundant statements
   - Cuts unnecessary qualifiers and hedging
   - Makes recommendations more actionable
   - Improves section flow

3. **Generates pipeline suggestions**
   - Additional metrics to capture
   - New insights to generate
   - Report structure improvements
   - Data capture enhancements

### Pipeline Changes

The orchestrator (`run_analysis.py`) now includes Step 7:

```
BEFORE (v3.5):
  report_v3.json → render_report.py → executive_summary.md

AFTER (v3.5.5):
  report_v3.json → render_report.py → executive_summary.md
                                           ↓
                                    review_report.py (Gemini 3 Pro)
                                           ↓
                            ┌──────────────┴──────────────┐
                            ↓                             ↓
              executive_summary_reviewed.md     pipeline_suggestions.md
```

### New CLI Arguments

```bash
# Skip the review step entirely
python3 tools/run_analysis.py --skip-review

# Use a different model for review
python3 tools/run_analysis.py --review-model gemini-2.5-flash

# Skip pipeline suggestions (review only)
python3 tools/run_analysis.py --no-suggestions
```

## Output Files

New files generated by the pipeline:

```
reports/
├── executive_summary_v3_{timestamp}.md           # Original (preserved)
├── executive_summary_v3_{timestamp}_reviewed.md  # Refined version
└── pipeline_suggestions_v3_{timestamp}.md        # Improvement ideas
```

## Reviewed Report Format

The reviewed report includes a header summarizing the editorial changes:

```markdown
---
## Report Review Summary

**Reviewed:** 2026-01-19 14:35 | **Model:** Gemini 3 Pro

### Refinements Made
- Consolidated redundant escalation findings into single coherent narrative
- Clarified relationship between verification failures and training gaps
- Tightened recommendations to be more actionable

### Data Quality Notes
- Unable to verify cross-correlation counts (would need raw data)
- Consider adding callback wait time metrics in future runs

---

[Original report content, refined...]
```

## Pipeline Suggestions Format

The suggestions file provides actionable improvement ideas:

```markdown
# Pipeline Improvement Suggestions

## Summary
Key opportunities exist in temporal analysis and customer journey tracking.

## Recommended Metrics to Add

### 1. Call Duration by Outcome
**Rationale:** Understand time cost of failures vs. successes
**Data source:** Already in transcripts (start/end timestamps)

## Recommended Insights to Add

### 1. Temporal Patterns
**Rationale:** Are certain failures more common at specific times?
**Approach:** Add time_of_day and day_of_week to analysis schema

## Report Structure Suggestions
- **Add "Quick Wins" section** - Separate high-impact, low-effort fixes

## Data Capture Improvements
- **conversation_turns** (analyze_transcript.py) - Proxy for complexity
```

## Usage

### Full Pipeline with Review

```bash
# Standard usage (review enabled by default)
python3 tools/run_analysis.py -n 50

# View both reports
cat reports/executive_summary_v3_*_reviewed.md
cat reports/pipeline_suggestions_v3_*.md
```

### Standalone Review

```bash
# Review an existing report
python3 tools/review_report.py -i reports/executive_summary_v3_20260119.md

# Review without suggestions
python3 tools/review_report.py --no-suggestions

# Print to stdout
python3 tools/review_report.py --stdout
```

### Skip Review (Cost Savings)

```bash
# Skip review to save API costs
python3 tools/run_analysis.py --skip-review
```

## Why This Design?

### Separate Tool (not integrated into render_report.py)
- **Modularity**: Can run review independently on any report
- **Skip-ability**: Easy to skip via `--skip-review` flag
- **Cost control**: Gemini 3 Pro is more expensive; make it optional
- **Audit trail**: Preserves original alongside refined version

### Why Gemini 3 Pro (not Flash)?
- Editorial review requires deeper reasoning
- Needs to hold full report in context and find inconsistencies
- Quality > speed for this step (runs once at end)

### Why Keep Original Report?
- Audit trail for what was generated vs. edited
- Allows comparison to understand review impact
- Rollback if review introduces issues

## Testing

```bash
# Run v3.5.5 feature tests
python3 tools/test_v355_features.py

# Run all tests
python3 tools/test_framework.py
```

## Migration from v3.5

No breaking changes. Existing workflows continue to work. Review is additive.

To opt-out of review:
```bash
python3 tools/run_analysis.py --skip-review
```

## Known Limitations

1. **Large reports may truncate**: Very long reports might hit token limits
2. **Number preservation**: While instructed to preserve numbers, always verify
3. **Suggestions are ideas**: Pipeline suggestions require human evaluation

## Files Changed

| File | Change |
|------|--------|
| `tools/review_report.py` | **NEW**: Editorial review and refinement tool |
| `tools/run_analysis.py` | Added Step 7, new CLI arguments |
| `tools/test_v355_features.py` | **NEW**: Unit tests for v3.5.5 features |
| `README_v3.5.5.md` | **NEW**: This release notes file |
